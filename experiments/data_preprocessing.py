"""
Speed Dating æ•°æ®é¢„å¤„ç†æ¨¡å—

åŠŸèƒ½:
1. åŠ è½½ Speed Dating æ•°æ®é›†
2. è¿‡æ»¤é«˜è´¨é‡æ ·æœ¬
3. æå–å…³é”®ç‰¹å¾
4. ç”Ÿæˆè®­ç»ƒ/æµ‹è¯•é…å¯¹
"""

import pandas as pd
import numpy as np
import json
from pathlib import Path
from typing import Dict, List, Tuple

class SpeedDatingDataProcessor:
    def __init__(self, data_path: str):
        """
        åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        
        Args:
            data_path: Speed Dating Data.csv çš„è·¯å¾„
        """
        self.data_path = data_path
        self.df = None
        self.clean_df = None
        self.pairs = []
        
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print("ğŸ“‚ Loading Speed Dating dataset...")
        self.df = pd.read_csv(self.data_path, encoding='latin1')
        print(f"âœ… Loaded {len(self.df)} records")
        print(f"   Columns: {self.df.shape[1]}")
        print(f"   Unique participants: {self.df['iid'].nunique()}")
        return self.df
    
    def filter_quality_samples(self):
        """
        è¿‡æ»¤é«˜è´¨é‡æ ·æœ¬ï¼ˆä¸­é«˜è¦†ç›–ç‡ç‰ˆæœ¬ >50%ï¼‰
        
        ä½¿ç”¨æ‰€æœ‰ä¸­ç­‰å’Œé«˜è¦†ç›–ç‡å­—æ®µï¼ˆ>50%ï¼‰ï¼Œæœ€å¤§åŒ–æ•°æ®å®Œæ•´æ€§
        
        å¿…éœ€å­—æ®µåˆ†ç»„:
        1. æ ¸å¿ƒä¿¡æ¯: demographics, background, dating behavior
        2. Time 1 å®Œæ•´æ•°æ®: preferences (self/opposite/same), self-ratings, others' perception
        3. å…´è¶£çˆ±å¥½: è‡³å°‘12ä¸ªæœ‰æ•ˆå€¼ (70%)
        4. Scorecard: å®Œæ•´è¯„åˆ†
        5. Ground truth: å†³ç­–å’ŒåŒ¹é…ç»“æœ
        """
        print("\nğŸ” Filtering quality samples (Medium-High coverage >50%)...")
        print("=" * 70)
        
        df = self.df.copy()
        initial_count = len(df)
        
        # 1. æ ¸å¿ƒäººå£ç»Ÿè®¡å­¦ï¼ˆ98-100% coverageï¼‰
        demographics = ['age', 'gender', 'field_cd', 'career_c', 'race']
        df = df.dropna(subset=demographics)
        print(f"   âœ… Demographics (5 fields): {len(df):,} / {initial_count:,} ({len(df)/initial_count*100:.1f}%)")
        
        # 2. èƒŒæ™¯æ€åº¦ï¼ˆ98-99% coverageï¼‰
        background = ['imprace', 'imprelig', 'goal', 'date', 'go_out']
        df = df.dropna(subset=background)
        print(f"   âœ… Background & behavior: {len(df):,} / {initial_count:,} ({len(df)/initial_count*100:.1f}%)")
        
        # 3. æœŸæœ›ï¼ˆåªè¦ exphappyï¼Œä¸è¦ expnum å› ä¸ºåªæœ‰21.5%ï¼‰
        df = df.dropna(subset=['exphappy'])
        print(f"   âœ… Expectations (exphappy): {len(df):,} / {initial_count:,} ({len(df)/initial_count*100:.1f}%)")
        
        # 4. è‡ªæˆ‘æ‹©å¶åå¥½ï¼ˆ99% coverageï¼‰
        preferences_self = ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']
        df = df.dropna(subset=preferences_self)
        print(f"   âœ… Preferences (self): {len(df):,} / {initial_count:,} ({len(df)/initial_count*100:.1f}%)")
        
        # 5. å¯¹å¼‚æ€§æ‹©å¶è§‚çš„é¢„æµ‹ï¼ˆ99% coverageï¼‰
        preferences_opposite = ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']
        df = df.dropna(subset=preferences_opposite)
        print(f"   âœ… Preferences (opposite sex): {len(df):,} / {initial_count:,} ({len(df)/initial_count*100:.1f}%)")
        
        # 6. å¯¹åŒæ€§æ‹©å¶è§‚çš„é¢„æµ‹ï¼ˆ77% coverage - ä¸­ç­‰ï¼‰
        preferences_same = ['attr4_1', 'sinc4_1', 'intel4_1', 'fun4_1', 'amb4_1', 'shar4_1']
        df = df.dropna(subset=preferences_same)
        print(f"   âš ï¸  Preferences (same sex): {len(df):,} / {initial_count:,} ({len(df)/initial_count*100:.1f}%)")
        
        # 7. è‡ªæˆ‘è¯„ä»·ï¼ˆ99% coverageï¼‰
        self_ratings = ['attr3_1', 'sinc3_1', 'intel3_1', 'fun3_1', 'amb3_1']
        df = df.dropna(subset=self_ratings)
        print(f"   âœ… Self-ratings: {len(df):,} / {initial_count:,} ({len(df)/initial_count*100:.1f}%)")
        
        # 8. ä»–äººçœ¼ä¸­çš„è‡ªå·±ï¼ˆ58.6% coverage - ä¸­ç­‰ï¼‰
        others_perception = ['attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1']
        df = df.dropna(subset=others_perception)
        print(f"   âš ï¸  Others' perception: {len(df):,} / {initial_count:,} ({len(df)/initial_count*100:.1f}%)")
        
        # 9. å…´è¶£çˆ±å¥½è‡³å°‘12ä¸ªæœ‰æ•ˆå€¼ï¼ˆé™ä½åˆ°70%ï¼Œæ›´å®½æ¾ï¼‰
        interests = ['sports', 'tvsports', 'exercise', 'dining', 'museums', 'art',
                    'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater',
                    'movies', 'concerts', 'music', 'shopping', 'yoga']
        df['valid_interests'] = df[interests].notna().sum(axis=1)
        df = df[df['valid_interests'] >= 12]  # 12/17 = 70%
        print(f"   âœ… Interests (â‰¥12/17): {len(df):,} / {initial_count:,} ({len(df)/initial_count*100:.1f}%)")
        
        # 10. Scorecard å®Œæ•´ï¼ˆåŒ…æ‹¬ sharï¼Œ87% coverage æ˜¯ç“¶é¢ˆï¼‰
        scorecard = ['attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like']
        df = df.dropna(subset=scorecard)
        print(f"   âš ï¸  Scorecard (7 fields): {len(df):,} / {initial_count:,} ({len(df)/initial_count*100:.1f}%)")
        
        # 11. å¿…é¡»æœ‰å†³ç­–å’ŒåŒ¹é…ç»“æœï¼ˆ100% coverageï¼‰
        df = df.dropna(subset=['dec', 'match'])
        print(f"   âœ… Ground truth: {len(df):,} / {initial_count:,} ({len(df)/initial_count*100:.1f}%)")
        
        print("=" * 70)
        
        self.clean_df = df
        print(f"\nğŸ‰ Final clean dataset: {len(df):,} records ({len(df)/initial_count*100:.1f}%)")
        print(f"   Unique participants: {df['iid'].nunique()}")
        print(f"   Average features per person: {len(df.columns)} columns")
        
        return df
    
    def extract_pairs(self, n_matched: int = 50, n_unmatched: int = 50):
        """
        æå–é…å¯¹æ ·æœ¬
        
        Args:
            n_matched: ç›®æ ‡åŒ¹é…å¯¹æ•°
            n_unmatched: ç›®æ ‡éåŒ¹é…å¯¹æ•°
        
        Returns:
            pairs: List[Dict] é…å¯¹ä¿¡æ¯
        """
        print(f"\nğŸ¯ Extracting {n_matched} matched + {n_unmatched} unmatched pairs...")
        
        df = self.clean_df
        pairs = []
        
        # è·å–æ‰€æœ‰äº’ç›¸è¯„ä»·çš„è®°å½•
        # å¯¹äºæ¯ä¸ª (iid, partner) å¯¹ï¼Œæ‰¾åˆ°å¯¹åº”çš„ (partner, iid) è®°å½•
        matched_pairs = []
        unmatched_pairs = []
        
        processed = set()
        
        for idx, row in df.iterrows():
            iid1 = row['iid']
            pid2 = row['pid']  # partnerçš„iid
            
            # é¿å…é‡å¤å¤„ç†
            pair_key = tuple(sorted([iid1, pid2]))
            if pair_key in processed:
                continue
            
            # æ‰¾åˆ°å¯¹æ–¹çš„è®°å½•
            partner_row = df[(df['iid'] == pid2) & (df['pid'] == iid1)]
            
            if len(partner_row) == 0:
                continue
            
            partner_row = partner_row.iloc[0]
            
            # æå–é…å¯¹ä¿¡æ¯ï¼ˆå…¨é¢ç‰ˆï¼‰
            pair_info = {
                'pair_id': f"pair_{len(pairs)+1:03d}",
                'person1': {
                    'iid': int(iid1),
                    'gender': int(row['gender']),
                    'age': int(row['age']),
                    'field_cd': int(row['field_cd']) if pd.notna(row['field_cd']) else None,
                    'career_c': int(row['career_c']) if pd.notna(row['career_c']) else None,
                    'race': int(row['race']) if pd.notna(row['race']) else None,
                    'imprace': int(row['imprace']) if pd.notna(row['imprace']) else None,
                    'imprelig': int(row['imprelig']) if pd.notna(row['imprelig']) else None,
                    'goal': int(row['goal']) if pd.notna(row['goal']) else None,
                    'date': int(row['date']) if pd.notna(row['date']) else None,
                    'go_out': int(row['go_out']) if pd.notna(row['go_out']) else None,
                    'data': row.to_dict()
                },
                'person2': {
                    'iid': int(pid2),
                    'gender': int(partner_row['gender']),
                    'age': int(partner_row['age']),
                    'field_cd': int(partner_row['field_cd']) if pd.notna(partner_row['field_cd']) else None,
                    'career_c': int(partner_row['career_c']) if pd.notna(partner_row['career_c']) else None,
                    'race': int(partner_row['race']) if pd.notna(partner_row['race']) else None,
                    'imprace': int(partner_row['imprace']) if pd.notna(partner_row['imprace']) else None,
                    'imprelig': int(partner_row['imprelig']) if pd.notna(partner_row['imprelig']) else None,
                    'goal': int(partner_row['goal']) if pd.notna(partner_row['goal']) else None,
                    'date': int(partner_row['date']) if pd.notna(partner_row['date']) else None,
                    'go_out': int(partner_row['go_out']) if pd.notna(partner_row['go_out']) else None,
                    'data': partner_row.to_dict()
                },
                'ground_truth': {
                    'person1_dec': int(row['dec']),
                    'person2_dec': int(partner_row['dec']),
                    'match': int(row['match']),
                    'person1_ratings': {
                        'attr': float(row['attr']),
                        'sinc': float(row['sinc']),
                        'intel': float(row['intel']),
                        'fun': float(row['fun']),
                        'amb': float(row['amb']),
                        'shar': float(row['shar']),
                        'like': float(row['like'])
                    },
                    'person2_ratings': {
                        'attr': float(partner_row['attr']),
                        'sinc': float(partner_row['sinc']),
                        'intel': float(partner_row['intel']),
                        'fun': float(partner_row['fun']),
                        'amb': float(partner_row['amb']),
                        'shar': float(partner_row['shar']),
                        'like': float(partner_row['like'])
                    }
                }
            }
            
            # åˆ†ç±»
            if pair_info['ground_truth']['match'] == 1:
                matched_pairs.append(pair_info)
            else:
                unmatched_pairs.append(pair_info)
            
            processed.add(pair_key)
        
        print(f"   Found {len(matched_pairs)} matched pairs")
        print(f"   Found {len(unmatched_pairs)} unmatched pairs")
        
        # é‡‡æ ·
        import random
        random.seed(42)
        
        selected_matched = random.sample(matched_pairs, min(n_matched, len(matched_pairs)))
        selected_unmatched = random.sample(unmatched_pairs, min(n_unmatched, len(unmatched_pairs)))
        
        self.pairs = selected_matched + selected_unmatched
        
        print(f"\nâœ… Selected {len(self.pairs)} pairs:")
        print(f"   - Matched: {len(selected_matched)}")
        print(f"   - Unmatched: {len(selected_unmatched)}")
        
        return self.pairs
    
    def save_processed_data(self, output_dir: str = "results"):
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # ä¿å­˜æ¸…æ´—åçš„æ•°æ®é›†
        clean_csv_path = output_path / "clean_dataset.csv"
        self.clean_df.to_csv(clean_csv_path, index=False)
        print(f"\nğŸ’¾ Saved clean dataset to {clean_csv_path}")
        
        # ä¿å­˜é…å¯¹ä¿¡æ¯
        pairs_json_path = output_path / "processed_pairs.json"
        with open(pairs_json_path, 'w', encoding='utf-8') as f:
            json.dump(self.pairs, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ Saved pairs to {pairs_json_path}")
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_records': len(self.df),
            'clean_records': len(self.clean_df),
            'unique_participants': int(self.clean_df['iid'].nunique()),
            'total_pairs': len(self.pairs),
            'matched_pairs': sum(1 for p in self.pairs if p['ground_truth']['match'] == 1),
            'unmatched_pairs': sum(1 for p in self.pairs if p['ground_truth']['match'] == 0),
            'age_distribution': self.clean_df['age'].describe().to_dict(),
            'gender_distribution': self.clean_df['gender'].value_counts().to_dict()
        }
        
        stats_path = output_path / "dataset_stats.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2)
        print(f"ğŸ’¾ Saved statistics to {stats_path}")
        
        return output_path


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ­ Speed Dating Data Preprocessing")
    print("=" * 50)
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    data_path = "Speed Dating Data.csv"
    processor = SpeedDatingDataProcessor(data_path)
    
    # åŠ è½½æ•°æ®
    processor.load_data()
    
    # è¿‡æ»¤é«˜è´¨é‡æ ·æœ¬
    processor.filter_quality_samples()
    
    # æå–é…å¯¹
    processor.extract_pairs(n_matched=50, n_unmatched=50)
    
    # ä¿å­˜ç»“æœ
    output_dir = processor.save_processed_data()
    
    print("\n" + "=" * 50)
    print("âœ… Data preprocessing completed!")
    print(f"ğŸ“ Results saved to: {output_dir}")
    print("\nğŸ¯ Next steps:")
    print("   1. Run persona_generator.py to create Persona prompts")
    print("   2. Run speed_dating_simulator.py for Scenario 1")
    print("   3. Run critical_events_engine.py for Scenario 2")


if __name__ == "__main__":
    main()
